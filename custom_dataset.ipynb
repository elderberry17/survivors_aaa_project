{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Import stuff"
      ],
      "metadata": {
        "id": "SdmV905Pd13T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "metadata": {
        "id": "SXe-ZqmPTZmR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load data"
      ],
      "metadata": {
        "id": "QWbmn4YXdue0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ekrbaFTW8F",
        "outputId": "56ffb31a-ada4-46d6-b6f4-77c401dbb8f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('./drive/MyDrive/AAA/course/avito_cv2vac_with_ranks.pq')"
      ],
      "metadata": {
        "id": "TP1YyznlTdU0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Make \"embeddings\""
      ],
      "metadata": {
        "id": "9jFX04Lfd9ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, 'vac_embed'] = 1\n",
        "df.loc[:, 'res_embed'] = 1\n",
        "\n",
        "df.loc[:, 'vac_embed'] = df['vac_embed'].apply(lambda x: torch.rand((128)))\n",
        "df.loc[:, 'res_embed'] = df['res_embed'].apply(lambda x: torch.rand((128)))"
      ],
      "metadata": {
        "id": "VI6aztI2TmMG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Make SiameseDataset and collate_fn"
      ],
      "metadata": {
        "id": "HsijgMN9d_SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseDataset(Dataset):\n",
        "  def __init__(self, df, vac_embed_column, res_embed_column, \n",
        "               res_des_column, label_column, rank_column, max_rank_column):\n",
        "    \"\"\"\n",
        "     Create dataset for Siamese Net training.\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     df : pd.DataFrame\n",
        "         the dataframe we create dataset from\n",
        "     vac_embed_column: str\n",
        "         name of the column of the vacancy embeddings\n",
        "     res_embed_column: str\n",
        "         name of the column of the resume embeddings\n",
        "     res_des_column: str\n",
        "         name of the column of the resume text description\n",
        "     label_column: str\n",
        "         name of the column of the vacancy embeddings\n",
        "     rank_column: str\n",
        "         name of the column of the resume rank \n",
        "     max_rank_column: str\n",
        "         name of the column of the max resumes rank for this vacancy \n",
        "        \n",
        "         Returns\n",
        "     -------\n",
        "     None\n",
        "     \"\"\"\n",
        "    self.df = df[[vac_embed_column, res_embed_column, label_column, rank_column, max_rank_column]]\n",
        "\n",
        "    self.vac_embed_column = vac_embed_column\n",
        "    self.res_embed_column = res_embed_column\n",
        "    self.label_column = label_column\n",
        "    self.rank_column = rank_column\n",
        "    self.max_rank_column = max_rank_column\n",
        "\n",
        "    # предполагаю, что каждое резюме кидается ровно на 1 вакансию, составляя одну пару\n",
        "    self.nunique_pairs = df[res_des_column].nunique()\n",
        "\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "     Return total amount of unique pairs: (vac_embed, res_embed).\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     None\n",
        "\n",
        "     Returns\n",
        "     -------\n",
        "     int\n",
        "         total amount of unique pairs: (vac_embed, res_embed) \n",
        "     \"\"\"\n",
        "    return self.nunique_pairs\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    '''\n",
        "     Return training object: (vac_embed, res_embed, label, rank, max_rank);\n",
        "     Return rank and max_rank to penalty most appropriate samples more.\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     idx: int\n",
        "         index of the samples we want to get.\n",
        "\n",
        "     Returns\n",
        "     -------\n",
        "     tuple[torch.tensor]\n",
        "         training object like a tuple: (vac_embed, res_embed, label, rank, max_rank)\n",
        "\n",
        "    '''\n",
        "    demandimg_row = self.df.iloc[idx, :]\n",
        "\n",
        "    return demandimg_row[self.vac_embed_column], demandimg_row[self.res_embed_column], \\\n",
        "           torch.tensor(demandimg_row[self.label_column]), torch.tensor(demandimg_row[self.rank_column]), torch.tensor(demandimg_row[self.max_rank_column])"
      ],
      "metadata": {
        "id": "AYmSkRqYWhxd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(data):\n",
        "    \"\"\"     \n",
        "     Make dict samples from tuples (it is easier to use);\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "       data: is a list of tuples with (vac_embed, res_embed, label, rank, max_rank)\n",
        "      \n",
        "    \"\"\"\n",
        "    vac_embed, res_embed, label, rank, max_rank = zip(*data)\n",
        "\n",
        "    dict_data = {'vac_embed': vac_embed, \n",
        "                 'res_embed': res_embed,\n",
        "                 'label': label,\n",
        "                 'rank': rank,\n",
        "                 'max_rank': max_rank}\n",
        "\n",
        "    return dict_data"
      ],
      "metadata": {
        "id": "8pDMQhLob8fD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create dataset amd dataloader instance "
      ],
      "metadata": {
        "id": "zzTxCaWJeEIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SiameseDataset(df, 'vac_embed', 'res_embed', 'res_des', 'label', 'rank', 'max_rank')"
      ],
      "metadata": {
        "id": "YmeuLlLwYB6f"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, 128, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "NTIWu4lXcvsc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Get a batch and overview it"
      ],
      "metadata": {
        "id": "Y7kV39kGeHtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataloader))"
      ],
      "metadata": {
        "id": "2EMu_v-RiJm_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# батч -- это словарь\n",
        "\n",
        "type(batch)"
      ],
      "metadata": {
        "id": "JmP4vX1SiUUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0f46af-b5f7-4a59-c513-1f9571e95c00"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# его ключи \n",
        "\n",
        "batch.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k78A7aZIdU6p",
        "outputId": "7eb9ef24-d6c2-47a2-911e-439ed4302209"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['vac_embed', 'res_embed', 'label', 'rank', 'max_rank'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# внутри каждого ключа кортеж длиной batch_size\n",
        "\n",
        "type(batch['vac_embed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvCjVTOJdSzz",
        "outputId": "95ade1c9-383e-4e26-e775-22a1c539bb37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(batch['vac_embed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMcBy76VdkHV",
        "outputId": "c82d617a-0d0c-4cab-862d-13b73b926159"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# каждый элемент уже то, что заявлено в ключах\n",
        "\n",
        "type(batch['vac_embed'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mYj1reUdlcB",
        "outputId": "239a17f1-b806-47fa-d3fa-cf8d6900b75e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# размерность эмбеддинга\n",
        "\n",
        "batch['vac_embed'][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6wN9O96dnYD",
        "outputId": "0e74adda-31f5-47ea-b54c-cb50723a0f8e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m74_DPZZdph3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}