{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "lkINH6Laj3B1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqwZGvnGAIh_",
        "outputId": "eaa82420-9dee-4812-dc2b-8eb47e7e4b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import random\n",
        "\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "NwFaUPnWDaWa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "pmsoaF5Dj6T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"./drive/MyDrive/AAA/course/data/avito_cv2vac_with_ranks_clear.pq\"\n",
        "SEED = 42\n",
        "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE = 'cpu'"
      ],
      "metadata": {
        "id": "2R_H2xX-jnGo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l {DATASET_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foYP-5LzlROZ",
        "outputId": "f4fa9743-62ca-4e32-b26c-c6d8d3045fb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 286631114 Apr  6 14:12 ./drive/MyDrive/AAA/course/data/avito_cv2vac_with_ranks_clear.pq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data (make splits)"
      ],
      "metadata": {
        "id": "Ll0hSd7oj9h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/AAA/course/data/val_id.pickle\", 'rb') as f:\n",
        "  val_id = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/AAA/course/data/test_id.pickle\", 'rb') as f:\n",
        "  test_id = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/AAA/course/data/train_id.pickle\", 'rb') as f:\n",
        "  train_id = pickle.load(f)"
      ],
      "metadata": {
        "id": "6x9fKIzr4yqI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_parquet(DATASET_PATH)"
      ],
      "metadata": {
        "id": "uY8_Jt1ywc1f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сделаем id для резюме, чтобы побиться по ним (чтобы на валидации при подсчете nDCG не было лика)\n",
        "\n",
        "# vac_to_id = dict(zip(df['vac_des'].unique(), range(df['vac_des'].nunique())))"
      ],
      "metadata": {
        "id": "cHRpqgTXxwZ7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['vac_id'] = df['vac_des'].apply(lambda x: vac_to_id[x])"
      ],
      "metadata": {
        "id": "uC5p0XMpyiaI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_parquet(DATASET_PATH)"
      ],
      "metadata": {
        "id": "IOxs2bRM6Fwx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "B4jWJv2G09Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataset(Dataset):\n",
        "  def __init__(self, df, vac_column, res_column, label_column):\n",
        "    \"\"\"\n",
        "     Create dataset for Siamese Net training.\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     df : pd.DataFrame\n",
        "         the dataframe we create dataset from\n",
        "     vac_column: str\n",
        "         name of the column of the vacancy\n",
        "     res_column: str\n",
        "         name of the column of the resume\n",
        "     label_column: str\n",
        "         name of the column of the vacancy embeddings\n",
        "\n",
        "         Returns\n",
        "     -------\n",
        "     None\n",
        "     \"\"\"\n",
        "    self.df = df[[vac_column, res_column, label_column]]\n",
        "\n",
        "    self.vac_column = vac_column\n",
        "    self.res_column = res_column\n",
        "    self.label_column = label_column\n",
        "\n",
        "    # предполагаю, что каждое резюме кидается ровно на 1 вакансию, составляя одну пару\n",
        "    self.nunique_pairs = df[res_column].nunique()\n",
        "\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "     Return total amount of unique pairs: (vac_embed, res_embed).\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     None\n",
        "\n",
        "     Returns\n",
        "     -------\n",
        "     int\n",
        "         total amount of unique pairs: (vac_embed, res_embed) \n",
        "     \"\"\"\n",
        "    return self.nunique_pairs\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    '''\n",
        "     Return training object: (vac_embed, res_embed, label, rank, max_rank);\n",
        "     Return rank and max_rank to penalty most appropriate samples more.\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "     idx: int\n",
        "         index of the samples we want to get.\n",
        "\n",
        "     Returns\n",
        "     -------\n",
        "     tuple[torch.tensor]\n",
        "         training object like a tuple: (vac_embed, res_embed, label, rank, max_rank)\n",
        "\n",
        "    '''\n",
        "    anchor_row = self.df.iloc[idx, :]\n",
        "    anchor_vac = anchor_row[self.vac_column]\n",
        "    anchor_label = anchor_row[self.label_column]\n",
        "\n",
        "    if anchor_label == 1:\n",
        "      positive_res = anchor_row[self.res_column]\n",
        "      negative_res = self.df.loc[(self.df[self.vac_column] == anchor_vac) & (self.df[self.label_column] == 0), self.res_column].iloc[0]\n",
        "\n",
        "    else:\n",
        "      negative_res = anchor_row[self.res_column]\n",
        "      positive_res = self.df.loc[(self.df[self.vac_column] == anchor_vac) & (self.df[self.label_column] == 1), self.res_column].iloc[0]\n",
        "\n",
        "    return anchor_vac, positive_res, negative_res"
      ],
      "metadata": {
        "id": "02kvI_QS0803"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(data):\n",
        "    \"\"\"     \n",
        "     Make dict samples from tuples (it is easier to use);\n",
        "\n",
        "     Parameters\n",
        "     ----------\n",
        "       data: is a list of tuples with (vac, pos_res, neg_res, label)\n",
        "      \n",
        "    \"\"\"\n",
        "    vac, pos_res, neg_res = zip(*data)\n",
        "\n",
        "    dict_data = {'vac': vac, \n",
        "                 'pos_res': pos_res,\n",
        "                 'neg_res': neg_res}\n",
        "                 \n",
        "    return dict_data"
      ],
      "metadata": {
        "id": "yNlqGa2J083A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = TripletDataset(df=df[df['vac_id'].isin(train_id)],\n",
        "#                                vac_column='vac_des', \n",
        "#                                res_column='res_des', \n",
        "#                                label_column='label')\n",
        "\n",
        "# val_dataset = TripletDataset(df=df[df['vac_id'].isin(val_id)],\n",
        "#                                vac_column='vac_des', \n",
        "#                                res_column='res_des', \n",
        "#                                label_column='label')\n",
        "\n",
        "# test_dataset = TripletDataset(df=df[df['vac_id'].isin(test_id)],\n",
        "#                                vac_column='vac_des', \n",
        "#                                res_column='res_des', \n",
        "#                                label_column='label')"
      ],
      "metadata": {
        "id": "0k1prG3E085U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/AAA/course/data/train_dataset.pickle\", \"rb\") as f:\n",
        "  train_dataset = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/AAA/course/data/val_dataset.pickle\", \"rb\") as f:\n",
        "  val_dataset = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/AAA/course/data/test_dataset.pickle\", \"rb\") as f:\n",
        "  test_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "isPIW3046MC-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make net\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVcAdubFPdZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# добавил функцию для создания эмбеддингов внутри\n",
        "\n",
        "class SiameseCVNet(nn.Module):\n",
        "  '''\n",
        "  i dont check dimensions and other stuff here\n",
        "  '''\n",
        "  def __init__(self, vac_vocab_size, res_vocab_size,\n",
        "               embedding_dim, rnn_hidden_dim, \n",
        "               hidden_layers, fc1_output=512, fc2_output=128):\n",
        "    \n",
        "    super(SiameseCVNet, self).__init__()\n",
        "\n",
        "    self.vac_vocab_size = vac_vocab_size\n",
        "    self.res_vocab_size = res_vocab_size\n",
        "\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.rnn_hidden_dim = rnn_hidden_dim\n",
        "    self.hidden_layers = hidden_layers\n",
        "    \n",
        "    # считаем после конкатенации в forward_one\n",
        "    self.fc1_input_one = 2 * (self.embedding_dim + (self.hidden_layers + 1) * self.rnn_hidden_dim)\n",
        "\n",
        "    # но мы конкатенируем 2 сэмпла!\n",
        "    self.fc1_input = 2 * self.fc1_input_one\n",
        "\n",
        "    self.fc1_output = fc1_output\n",
        "    self.fc2_output = fc2_output\n",
        "\n",
        "    self.vac_embed = nn.Embedding(vac_vocab_size, embedding_dim)\n",
        "    self.res_embed = nn.Embedding(res_vocab_size, embedding_dim)\n",
        "\n",
        "    self.rnn = nn.LSTM(input_size=embedding_dim,\n",
        "                       hidden_size=rnn_hidden_dim,\n",
        "                       num_layers=hidden_layers,\n",
        "                       batch_first=True)\n",
        "    \n",
        "    fc1 = nn.Linear(self.fc1_input, self.fc1_output)\n",
        "    relu = nn.ReLU()\n",
        "    fc2 = nn.Linear(self.fc1_output, self.fc2_output)\n",
        "    sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.nn_head = nn.Sequential(\n",
        "        fc1,\n",
        "        relu,\n",
        "        fc2,\n",
        "        sigmoid\n",
        "        \n",
        "      ) \n",
        "\n",
        "  def forward(self, vac_text, res_text):\n",
        "    vac_embeds = self.vac_embed(vac_text)\n",
        "    res_embeds = self.res_embed(res_text)\n",
        "\n",
        "    catted_output_vac = self.forward_one(vac_embeds)\n",
        "    catted_output_res = self.forward_one(res_embeds)\n",
        "\n",
        "    # конкатенируем и пускаем через dense\n",
        "\n",
        "    catted_output = torch.cat((catted_output_vac, catted_output_res), dim=-1)\n",
        "    sigm_output = self.nn_head(catted_output)\n",
        "\n",
        "    return sigm_output\n",
        "\n",
        "  def forward_one(self, batch):\n",
        "    '''\n",
        "    image there is just a tensor of embeddings\n",
        "    shit with dims for sure\n",
        "    '''\n",
        "\n",
        "    # print('sample:', batch.shape)\n",
        "\n",
        "    rnn_output, (hidden_states, cell_states) = self.rnn(batch)\n",
        "\n",
        "    # print('rnn output:', rnn_output.shape)\n",
        "\n",
        "    embed_max_pool = batch.max(dim=1)[0]\n",
        "    embed_avg_pool = batch.sum(dim=1) / len(batch)\n",
        "\n",
        "    rnn_max_pool = rnn_output.max(dim=1)[0]\n",
        "    rnn_avg_pool = rnn_output.sum(dim=1) / len(rnn_output)  \n",
        "\n",
        "    # print('embed pool:', embed_max_pool.shape, embed_avg_pool.shape)\n",
        "    # print('rnn output pool:', rnn_max_pool.shape, rnn_max_pool.shape) \n",
        "    # print('hidden and state: ', hidden_states.shape, cell_states.shape)\n",
        "\n",
        "    # тут 0 ось -- кол-во слоев в rnn-блоке\n",
        "    hidden_states = torch.cat([hidden_states[i, :, :] for i in range(hidden_states.shape[0])], dim=-1)\n",
        "    cell_states = torch.cat([cell_states[i, :, :] for i in range(cell_states.shape[0])], dim=-1)\n",
        "\n",
        "    # print('hidden and state: ', hidden_states.shape, cell_states.shape)\n",
        "\n",
        "    catted_output = torch.cat((embed_max_pool, embed_avg_pool, rnn_max_pool, \n",
        "                              rnn_avg_pool, hidden_states, cell_states), dim=-1)\n",
        "\n",
        "    return catted_output "
      ],
      "metadata": {
        "id": "pvOB2PavPc0_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c = 0\n",
        "\n",
        "# for batch in loader:\n",
        "#   vac = batch[\"vac\"]\n",
        "#   pos_res = batch[\"pos_res\"]\n",
        "#   neg_res = batch[\"neg_res\"]\n",
        "\n",
        "#   vac_ind = make_indexes_from_tuple(vac, vac_vocab).to(DEVICE)\n",
        "#   pos_res_ind = make_indexes_from_tuple(pos_res, res_vocab).to(DEVICE)\n",
        "\n",
        "#   neg_res_ind = make_indexes_from_tuple(neg_res, res_vocab).to(DEVICE)\n",
        "\n",
        "#   pos_sim = model(vac_ind, pos_res_ind)\n",
        "#   neg_sim = model(vac_ind, neg_res_ind)\n",
        "\n",
        "#   print(neg_res_ind.shape)\n",
        "\n",
        "#   c += 1\n",
        "#   if c == 10:\n",
        "#     break\n",
        "\n",
        "\n",
        "#     # 2 * embed + 2 * hidden + 2 * layers * hidden"
      ],
      "metadata": {
        "id": "ANSAwxXrJ_0_"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2c_PLKTnJ_31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Vocab"
      ],
      "metadata": {
        "id": "Lh6gjM27QBwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgrF1LWMQDrg",
        "outputId": "b934abd7-35ad-4c92-f428-8ff4cb734cb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.5.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting slovnet>=0.6.0\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.1-py3-none-any.whl (33 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from navec>=0.9.0->natasha) (1.22.4)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Building wheels for collected packages: docopt, intervaltree\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=8645373ae8f659a356bc1bd991cdb27bceb36b008796737948d140f1761de8ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26114 sha256=de38f92841990deeb19c66a4e262cba64e43c884dab3687235fdcb278669912f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/fa/1b/75d9a713279796785711bd0bad8334aaace560c0bd28830c8c\n",
            "Successfully built docopt intervaltree\n",
            "Installing collected packages: razdel, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.5.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.6.0 yargy-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Segmenter, Doc"
      ],
      "metadata": {
        "id": "jE5OG3zFQE7a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# vac_texts = []\n",
        "# res_texts = []\n",
        "\n",
        "segmenter = Segmenter()"
      ],
      "metadata": {
        "id": "ui-zSPiqRtJM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# запоминаем vocab на train'е\n",
        "\n",
        "# for vac_text, res_text, _ in iter(train_dataset):\n",
        "#     vac_doc = Doc(vac_text)\n",
        "#     vac_doc.segment(segmenter)\n",
        "#     vac_tokens = [token.text for token in vac_doc.tokens]\n",
        "#     vac_texts.extend([token.lower() for token in vac_tokens])\n",
        "\n",
        "#     res_doc = Doc(res_text)\n",
        "#     res_doc.segment(segmenter)\n",
        "#     res_tokens = [token.text for token in res_doc.tokens]\n",
        "#     res_texts.extend([token.lower() for token in res_tokens])"
      ],
      "metadata": {
        "id": "lGGnyx5rQA-1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(vac_texts), len(res_texts)"
      ],
      "metadata": {
        "id": "ggJfq3HeUD-s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вокабы\n",
        "\n",
        "# vac_vocab = {token: ind for ind, token in enumerate(list(set(vac_texts)))}\n",
        "# res_vocab = {token: ind for ind, token in enumerate(list(set(res_texts)))}"
      ],
      "metadata": {
        "id": "JHNx-khadLNq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(vac_vocab), len(res_vocab)"
      ],
      "metadata": {
        "id": "Gxb5YxT_dLP1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/AAA/course/data/vac_vocab.pickle\", 'rb') as f:\n",
        "  vac_vocab = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/AAA/course/data/res_vocab.pickle\", 'rb') as f:\n",
        "  res_vocab = pickle.load(f)"
      ],
      "metadata": {
        "id": "kH8Xc37biPRZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First attempts"
      ],
      "metadata": {
        "id": "U5ZZm5lqWJRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    \n",
        "    def forward(self, pos_sim: torch.Tensor, neg_sim: torch.Tensor) -> torch.Tensor:\n",
        "        losses = torch.relu(neg_sim - pos_sim + self.margin)\n",
        "        \n",
        "        return losses.mean()"
      ],
      "metadata": {
        "id": "LIi9d_iroxyU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_indexes_from_tuple(t, vocab):\n",
        "  '''\n",
        "  костыли на костылях!!\n",
        "  '''\n",
        "  indexes = []\n",
        "  for sent in t:\n",
        "    sent = Doc(sent)\n",
        "    sent.segment(segmenter) \n",
        "    ind = np.array([vocab.get(token.text.lower()) for token in sent.tokens], dtype=np.float16)\n",
        "\n",
        "    ind = np.nan_to_num(ind, nan=0)\n",
        "    ind = torch.LongTensor(ind)\n",
        "\n",
        "    indexes.append(ind)\n",
        "  \n",
        "  padded_indexes = nn.utils.rnn.pad_sequence(indexes, padding_value=0, batch_first=True)\n",
        "  return padded_indexes"
      ],
      "metadata": {
        "id": "ZnH64qplZ2P_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, dataset, batch_size, shuffle, collate_fn, \n",
        "                verbose_every_n_batches=300):\n",
        "    \n",
        "    torch_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
        "    loss = TripletLoss(margin=1)\n",
        "\n",
        "    total_train_loss = 0\n",
        "    num_batches = 1\n",
        "    \n",
        "    model = model.to(DEVICE)\n",
        "    model.train()\n",
        "    \n",
        "    for batch in tqdm(torch_dataloader, desc=\"Training\"):   \n",
        "        vac, pos_res, neg_res = batch[\"vac\"], batch[\"pos_res\"], batch[\"neg_res\"]   \n",
        "        vac_ind = make_indexes_from_tuple(vac, vac_vocab).to(DEVICE)\n",
        "        pos_res_ind = make_indexes_from_tuple(pos_res, res_vocab).to(DEVICE)\n",
        "        neg_res_ind = make_indexes_from_tuple(neg_res, res_vocab).to(DEVICE)\n",
        "\n",
        "        pos_sim = model(vac_ind, pos_res_ind)\n",
        "        neg_sim = model(vac_ind, neg_res_ind)\n",
        "\n",
        "        batch_loss = loss(pos_sim, neg_sim)\n",
        "        \n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        total_train_loss += batch_loss * batch_size\n",
        "        \n",
        "        if num_batches == 1:\n",
        "            print(f\"Train loss after first batch: {total_train_loss}\", end='\\r')    \n",
        "        \n",
        "        if num_batches % verbose_every_n_batches == 0:\n",
        "            print(f\"Mean train loss on the last {verbose_every_n_batches} batches: {total_train_loss / verbose_every_n_batches};\", end=\"\\r\")\n",
        "            \n",
        "        num_batches += 1\n",
        "            \n",
        "    print(f\"Mean train loss after epoch: {total_train_loss / num_batches}\")\n",
        "    print(f\"Total train loss after epoch: {total_train_loss}\")\n",
        "  \n",
        "\n",
        "# по хорошему эту функцию надо будет менять, если хотим считать nDCG\n",
        "def eval_model(model, dataset, batch_size, collate_fn, \n",
        "               verbose_every_n_batches=300):\n",
        "    torch_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "    preds, targets = [], []\n",
        "    \n",
        "    total_valid_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm(torch_dataloader, desc=\"Evaluating\"):\n",
        "        vac, pos_res, neg_res = batch[\"vac\"], batch[\"pos_res\"], batch[\"neg_res\"]\n",
        "        pos_sim = model(vac, pos_res)\n",
        "        neg_sim = model(vac, neg_res)\n",
        "\n",
        "        preds.extend(pos_sim)\n",
        "        targets.extend(np.ones(pos_sim.shape))\n",
        "        preds.extend(neg_sim)\n",
        "        targets.extend(np.zeros(neg_sim.shape))\n",
        "\n",
        "    return targets, preds"
      ],
      "metadata": {
        "id": "F4r6K23W7NHJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_cuda_cache():\n",
        "  start_available, reserved = torch.cuda.mem_get_info()\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  fin_available, reserved = torch.cuda.mem_get_info()\n",
        "  print(f\"cleaned {(fin_available - start_available) / 2**10} gb\")\n",
        "  print(f\"available {fin_available / 2**10} gb\")"
      ],
      "metadata": {
        "id": "ZrFiKeaUASLH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_loop(\n",
        "    model, optimizer, scheduler, \n",
        "    dataset_train, dataset_val, dataset_test,\n",
        "    batch_size_train, batch_size_test, batch_size_val,\n",
        "    num_epochs, train_shuffle, collate_fn, \n",
        "    verbose_every_n_batches, eval_on_train, \n",
        "    early_stopping_patience=7\n",
        "):\n",
        "\n",
        "    for n_epoch in range(1, num_epochs + 1):\n",
        "        train_epoch(\n",
        "                    model=model, \n",
        "                    optimizer=optimizer, \n",
        "                    dataset=dataset_train, \n",
        "                    batch_size=batch_size_train, \n",
        "                    shuffle=train_shuffle, \n",
        "                    collate_fn=collate_fn, \n",
        "                    verbose_every_n_batches=verbose_every_n_batches\n",
        "                  )\n",
        "                    \n",
        "        # clean cache before validation    \n",
        "        clean_cuda_cache()    \n",
        "            \n",
        "        targets_val, preds_val = eval_model(\n",
        "            model=model,\n",
        "            dataset=dataset_val,\n",
        "            batch_size=batch_size_val,\n",
        "            collate_fn=collate_fn\n",
        "        )\n",
        "        \n",
        "        # for logging while validating\n",
        "        loss = TripletLoss(margin=1)\n",
        "            \n",
        "        # count common loss\n",
        "        val_loss = loss(torch.tensor(targets_val), torch.tensor(preds_val))\n",
        "        \n",
        "        with open(LOGGING_FILE_PATH, 'a') as f:\n",
        "            f.write(f'epoch {n_epoch}. valid loss: {val_loss}\\n')\n",
        "\n",
        "        # torch.save(model.state_dict(), os.path.join(EXP_CHECKPOINTS_PATH, f\"epoch_{n_epoch}_{datetime.now().strftime('%Y-%m-%d')}_{datetime.now().strftime('%H:%M:%S')}_testCC_{round(test_roc_auc_CC, 3)}_testPIL_{round(test_roc_auc_PIL, 3)}.pt\"))\n",
        "                \n",
        "        targets_test, preds_test = eval_model(\n",
        "            model=model,\n",
        "            dataset=dataset_test,\n",
        "            batch_size=batch_size_test,\n",
        "            collate_fn=collate_fn\n",
        "        )\n",
        "        \n",
        "        # count common loss\n",
        "        test_loss = loss(torch.tensor(targets_test), torch.tensor(preds_test))\n",
        "        \n",
        "        with open(LOGGING_FILE_PATH, 'a') as f:\n",
        "            f.write(f'epoch {n_epoch}. test loss: {test_loss}\\n')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        if eval_on_train:\n",
        "                targets_train, preds_train = eval_model(\n",
        "                model=model,\n",
        "                dataset=dataset_train,\n",
        "                batch_size=batch_size_train,\n",
        "                collate_fn=collate_fn\n",
        "            )\n",
        "            \n",
        "                # count common loss\n",
        "                train_loss = loss(torch.tensor(targets_train), torch.tensor(preds_train))\n",
        "                \n",
        "                with open(LOGGING_FILE_PATH, 'a') as f:\n",
        "                    f.write(f'epoch {n_epoch}. train loss: {train_loss}\\n')\n",
        "\n",
        "        print(35 * \"=\" + \"\\n\")\n"
      ],
      "metadata": {
        "id": "AD_rxRXN71mE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXP_PATH = f\"./drive/MyDrive/AAA/course/checkpoints/first_{date.today().strftime('%d/%m/%Y').replace('/', '_')}/\"\n",
        "LOGGING_FILE_PATH = EXP_PATH + 'logs.txt'\n",
        "\n",
        "! mkdir {EXP_PATH}\n",
        "! touch {LOGGING_FILE_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb_QxDW9BBgn",
        "outputId": "6a385538-616c-4c70-b044-bd6d4d34fb89"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘./drive/MyDrive/AAA/course/checkpoints/first_06_04_2023/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_parameters = {\n",
        "    \"embedding_dim\": 128,\n",
        "    \"rnn_hidden_dim\": 512,\n",
        "    \"hidden_layers\": 1,\n",
        "    \"fc1_output\": 256,\n",
        "    \"fc2_output\": 128,\n",
        "    \"vac_vocab_size\": len(vac_vocab),\n",
        "    \"res_vocab_size\": len(res_vocab),\n",
        "}\n",
        "\n",
        "# похоже, на 512 уже не вывозит\n",
        "experement_parameters = {\n",
        "    \"optimizer_lr\": 1e-4,\n",
        "    \"optimizer_weight_decay\": 1e-4,\n",
        "    \"scheduler_patience\": 5,\n",
        "    \"scheduler_factor\": 0.8,\n",
        "    \"dataset_train\": train_dataset,\n",
        "    \"dataset_test\": val_dataset,\n",
        "    \"dataset_val\": test_dataset,\n",
        "    \"batch_size_train\": 64, \n",
        "    \"batch_size_val\": 64, \n",
        "    \"batch_size_test\": 64,\n",
        "    \"num_epochs\": 50,\n",
        "    \"train_shuffle\": True,\n",
        "    \"collate_fn\": collate_fn,\n",
        "    \"verbose_every_n_batches\": 300,\n",
        "    \"eval_on_train\": False,\n",
        "}\n",
        "\n",
        "# надо будет размерности чинить\n",
        "model = SiameseCVNet(\n",
        "    embedding_dim=model_parameters[\"embedding_dim\"],\n",
        "    vac_vocab_size=model_parameters[\"vac_vocab_size\"],\n",
        "    res_vocab_size=model_parameters[\"res_vocab_size\"],    \n",
        "    rnn_hidden_dim=model_parameters[\"rnn_hidden_dim\"],\n",
        "    hidden_layers=model_parameters[\"hidden_layers\"],\n",
        "    fc1_output=model_parameters[\"fc1_output\"],\n",
        "    fc2_output=model_parameters[\"fc2_output\"]\n",
        ")\n",
        "\n",
        "# классика\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=model.parameters(),\n",
        "    lr=experement_parameters[\"optimizer_lr\"],\n",
        "    weight_decay=experement_parameters[\"optimizer_weight_decay\"]\n",
        ")\n",
        "\n",
        "# норм оптимайзер вроде\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer,\n",
        "    patience=experement_parameters[\"scheduler_patience\"],\n",
        "    factor=experement_parameters[\"scheduler_factor\"]\n",
        ")\n",
        "\n",
        "loss = TripletLoss(margin=1)"
      ],
      "metadata": {
        "id": "0SUAX2p7-gnc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cpu'"
      ],
      "metadata": {
        "id": "ijJ78f8pRaaD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_loop(\n",
        "  model=model, optimizer=optimizer, scheduler=scheduler, \n",
        "  dataset_train=experement_parameters[\"dataset_train\"], \n",
        "  dataset_test=experement_parameters[\"dataset_test\"], \n",
        "  dataset_val=experement_parameters[\"dataset_val\"],\n",
        "  batch_size_train=experement_parameters[\"batch_size_train\"],\n",
        "  batch_size_val=experement_parameters[\"batch_size_val\"], \n",
        "  batch_size_test=experement_parameters[\"batch_size_test\"],\n",
        "  num_epochs=experement_parameters[\"num_epochs\"], \n",
        "  train_shuffle=experement_parameters[\"train_shuffle\"], \n",
        "  collate_fn=experement_parameters[\"collate_fn\"], \n",
        "  verbose_every_n_batches=experement_parameters[\"verbose_every_n_batches\"],\n",
        "  eval_on_train=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX_vI4Ae-y2Z",
        "outputId": "1c55634b-017a-44a7-c0c8-616703c9658f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/952 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4vJ99EtvJ7c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}